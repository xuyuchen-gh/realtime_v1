# 三性六讲
## 自我介绍
> 面试官你好我叫徐震....（发挥 30S左右 做什么项目 用什么平台 语言 用来做什么）

## 项目介绍

### 实时

#### 数据源,数据通道(pipLine),target 

#### ETL ELT ELK
>1. ETL (Extract, Transform, Load)
    ETL 是一种数据集成过程，它包括三个主要步骤：抽取（Extract）、转换（Transform）和加载（Load）。这个过程通常用于将来自多个异构数据源的数据整合到一个集中的存储库中，比如数据仓库。在这个过程中，数据首先从不同的源系统中抽取出来，然后经过一系列的清洗、验证和转换操作以确保数据的一致性和准确性，最后加载到目标系统中供进一步的分析使用。
>2. ELT (Extract, Load, Transform)
    ELT 与 ETL 类似，但顺序略有不同。在 ELT 流程中，数据先被抽取并直接加载到目标系统（通常是云数据仓库），然后再进行转换。这种方法允许更快地获取原始数据，并利用目标系统的计算能力来进行数据转换。随着云计算的发展，ELT 已经变得越来越流行，因为它可以更好地利用云端的强大计算资源。
>3. ELK (Elasticsearch, Logstash, Kibana)
    ELK 并不是一个数据集成过程，而是一个开源工具组合，也被称为“Elastic Stack”，用于日志管理和分析。它由三个组件组成：
Elasticsearch：一个分布式搜索和分析引擎，适用于各种类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。
Logstash：一个服务器端数据处理管道，能够同时从多个来源采集数据，对其进行转换，然后将其发送到指定的“存储库”或输出。
Kibana：一个可视化工具，使用户能够通过图表、表格和其他视觉元素来探索 Elasticsearch 中的数据。
ELK 堆栈常用于收集、分析和可视化大量的日志信息，帮助开发者和运维人员监控系统健康状况，快速诊断问题，以及进行数据分析。

#### 讲指标和需求 

#### 状态处理 维度join 


### 离线

#### SQL复杂指标 数据建模。。。。

#### 设计优化 组件对比

#### 报表

